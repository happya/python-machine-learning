<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>LR_Notes.mdâ€”C:\Users\pc39\OneDrive - HKUST Connect\DNN\python-machine-learning\logReg</title>
    <link rel="stylesheet" type="text/css" href="/public/github.css">
  </head>
  <body>
    <div class="container">
      <div id="markup">
        <article id="content" class="markdown-body">
          <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<h1>linear Regression</h1>
<p>Datesets: <mathjax>$D=\{(x_1,y_1),...(x_m,y_m)\}$</mathjax></p>
<p>prediction: <mathjax>$\hat y= wx_i+b$</mathjax></p>
<p>cost function: <mathjax>$E(w,b)=\sum_{i=1}^{m}(y_i-wx_i-b)^2$</mathjax></p>
<p>minimize cost function:</p>
<p><mathjax>$\frac{\partial E}{\partial w}=2(w\sum_{i=1}^{m}x_i^2-\sum_{i=1}^{m}(y_i-b)x_i)=0$</mathjax></p>
<p><mathjax>$\frac{\partial E}{\partial b}=2(mb-\sum_{i=1}^{m}(y_i-wx_i))=0$</mathjax></p>
<p>so,</p>
<p><mathjax>$b=\frac{1}{m}\sum_{i=1}^{m}(y_i-wx_i)$</mathjax></p>
<p><mathjax>$mw\sum_{i=1}^{m}x_i^2=m\sum_{i=1}^{m}y_i(x_i-\overline x)+(\sum_{i=1}^{m}x_i)^2$</mathjax></p>
<p>then,
<mathjax>$w=\frac{\sum_{i=1}^{m}y_i(x_i-\overline x)}{\sum_{i=1}^{m}x_i^2-\frac{1}{m}(\sum_{i=1}^{m}x_i)^2}$</mathjax></p>
<h2>least square</h2>
<p><mathjax>$x$</mathjax> is a multivariable with a dimension of <mathjax>$d$</mathjax>, with the expression of <mathjax>$x_i=(x_{i1},...x_{id})$</mathjax>, then the dataset can be expressed as a matrix <mathjax>$X$</mathjax> as:
<mathjax>$$
\left\{
\begin{matrix}
x_{11}&amp;...&amp;x_{1d}&amp;1\\
x_{21}&amp;...&amp;x_{2d}&amp;1\\
\vdots  &amp; \ddots &amp; \vdots \\
x_{m1}&amp;...&amp;x_{md}&amp;1
\end{matrix}
\right\}
=
\left\{
\begin{matrix}
x_1^T&amp;1\\
x_2^T&amp;1\\
\vdots&amp;\vdots\\
x_m^T&amp;1
\end{matrix}
\right\}
$$</mathjax>
and the label can also be written as vector <mathjax>$y=(y_1,...,y_m)^T$</mathjax>, then the predicted <mathjax>$w$</mathjax> is also a vector with the expression <mathjax>$\hat w=(w,b)$</mathjax>, and the predicted label <mathjax>$\hat y=X\hat w$</mathjax></p>
<p>cost function:</p>
<p><mathjax>$E_{\hat w}=(y-X\hat w)^T(y-X\hat w)$</mathjax></p>
<p><mathjax>$\frac{\partial E_{\hat w}}{\partial \hat w}=2X^T(X\hat w-y)=0$</mathjax></p>
<p>if <mathjax>$X^TX$</mathjax> is full-rank matrix or positive definite determined matrix, we can obtain:</p>
<p><mathjax>$\hat w^* = (X^Tx)^{-1}x^Ty$</mathjax></p>
<h2>regularization terms</h2>
<p>Since <mathjax>$X^Tx$</mathjax> can be non-full-rank, we can introducte regularization terms.</p>
        </article>
      </div>
    </div>
  </body>
  <script type="text/x-omnimarkup-config">
    window.App.Context = {
      buffer_id: 79,
      timestamp: '1545191306.245375',
      revivable_key: 'QzpcVXNlcnNccGMzOVxPbmVEcml2ZSAtIEhLVVNUIENvbm5lY3RcRE5OXHB5dGhvbi1tYWNoaW5lLWxlYXJuaW5nXGxvZ1JlZ1xMUl9Ob3Rlcy5tZA=='
    };
    window.App.Options = {
      ajax_polling_interval: 500,
      mathjax_enabled: true
    };
  </script>
  <script type="text/javascript" src="/public/jquery-2.1.3.min.js"></script>
  <script type="text/javascript" src="/public/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript" src="/public/app.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
          processEscapes: true
        },
        TeX: {
          equationNumbers: {
            autoNumber: 'AMS'
          }
        },
        'HTML-CSS': {
          imageFont: null
        }
      });
  </script>
  <script type="text/javascript" src="/public/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</html>
